{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, 33+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val),\n",
    "                  'z{}'.format(val), 'v{}'.format(val)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a VideoCapture object and read from the input file\n",
    "cap = cv2.VideoCapture('./videos/stool.avi')\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "  print(\"Error opening video file\")\n",
    "  exit()\n",
    "\n",
    "# Read until video is completed\n",
    "while cap.isOpened():\n",
    "  # Capture frame-by-frame\n",
    "  ret, frame = cap.read()\n",
    "\n",
    "  # If the frame is not read correctly, break\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  # Display the resulting frame\n",
    "  cv2.imshow(\"Video\", frame)\n",
    "\n",
    "  # Press Q on keyboard to exit\n",
    "  if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "    break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STANDING = 0\n",
    "RIGHT_LIFT = 1\n",
    "LEFT_LIFT = 2\n",
    "def detect_step(action,action_array,count_dict):\n",
    "    print(action_array)\n",
    "    if len(action_array) == 0 and action != STANDING:\n",
    "        return\n",
    "    if len(action_array) == 0 or action_array[-1] != action:\n",
    "        action_array.append(action)\n",
    "    if len(action_array) == 3:\n",
    "        print(action_array)\n",
    "        first_element,second_element,third_element = action_array\n",
    "        if first_element == STANDING and second_element == RIGHT_LIFT and third_element == STANDING:\n",
    "            count_dict['right'] += 1\n",
    "        if first_element == STANDING and second_element == LEFT_LIFT and third_element == STANDING:\n",
    "            count_dict['left'] += 1\n",
    "        action_array.clear()\n",
    "    return\n",
    "\n",
    "def stepping_on_stool(req_angles,count_dict,action_array):\n",
    "    left_stand_flag = False\n",
    "    right_stand_flag = False\n",
    "\n",
    "    left_lift_flag = False\n",
    "    right_lift_flag = False\n",
    "\n",
    "    standing_position = 180\n",
    "    lifted_postition = 135\n",
    "    left_knee_angle = req_angles[6]\n",
    "    right_knee_angle = req_angles[7]\n",
    "    if standing_position - epsilon_knee <= left_knee_angle <= standing_position + epsilon_knee:\n",
    "        # print('left leg in standing position')\n",
    "        left_stand_flag = True\n",
    "        left_lift_flag = False\n",
    "    if standing_position - epsilon_knee <= right_knee_angle <= standing_position + epsilon_knee:\n",
    "        right_stand_flag = True\n",
    "        right_lift_flag = False\n",
    "        # print('right leg in standing position')\n",
    "\n",
    "    if lifted_postition - epsilon_knee <= left_knee_angle <= lifted_postition + epsilon_knee:\n",
    "        # print('left leg in standing position')\n",
    "        left_lift_flag = True\n",
    "        left_stand_flag = False\n",
    "    if lifted_postition - epsilon_knee <= right_knee_angle <= lifted_postition + epsilon_knee:\n",
    "        right_lift_flag = True\n",
    "        right_stand_flag = False\n",
    "        # print('right leg in standing position')\n",
    "    if left_stand_flag and right_stand_flag:\n",
    "        print(\"Person is standing.\")\n",
    "        detect_step(STANDING,action_array,count_dict)\n",
    "    if left_stand_flag and right_lift_flag:\n",
    "        print(\"Person has placed right foot on stool.\")\n",
    "        detect_step(RIGHT_LIFT,action_array,count_dict)\n",
    "    if right_stand_flag and left_lift_flag:\n",
    "        print('Person has placed left foot on stool.')\n",
    "        detect_step(LEFT_LIFT,action_array,count_dict)\n",
    "\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ALGORITHM HYPER PARAMETERS########\n",
    "epsilon_knee = 10\n",
    "epsilon_rest_of_the_body = 5\n",
    "###FLAGS###\n",
    "start_flag = False\n",
    "count_dict = dict({'left':0,'right':0})\n",
    "action_array = []\n",
    "##########################################\n",
    "cap = cv2.VideoCapture('./videos/stool.avi')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# text = \"Hello, OpenCV!\"\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = holistic.process(image)\n",
    "\n",
    "    # Draw landmark annotation on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.pose_landmarks,\n",
    "        mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles\n",
    "        .get_default_pose_landmarks_style())\n",
    "    \n",
    "    try:\n",
    "      ######################################################\n",
    "      #Extract Joint coordinates\n",
    "      my_landmarks = results.pose_landmarks.landmark\n",
    "      joint_coordinates = get_coordinates(my_landmarks)\n",
    "      #calculate joint angles\n",
    "      req_angles = get_all_angles(joint_coordinates)\n",
    "      req_angles = np.around(req_angles,2)\n",
    "      #display joint angles\n",
    "      for i in range(len(req_angles)):\n",
    "          cv2.putText(\n",
    "              image,\n",
    "              str(req_angles[i]),\n",
    "              tuple(np.multiply(joint_coordinates[i][1],[640, 480]).astype(int)),\n",
    "              cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2,cv2.LINE_AA\n",
    "          )\n",
    "      left_knee_angle = req_angles[6]\n",
    "      right_knee_angle = req_angles[7]\n",
    "      key = cv2.waitKey(1) & 0xFF\n",
    "      if key == ord('s'):\n",
    "         print('Exercise Started')\n",
    "         start_flag = True\n",
    "      # print(\"The left Knee angle is: \",left_knee_angle)\n",
    "      # print(\"The right Knee angle is: \",right_knee_angle)\n",
    "      if start_flag:\n",
    "         res = stepping_on_stool(req_angles,count_dict,action_array)\n",
    "         if res:\n",
    "          # print(res)\n",
    "          left_count = res['left']\n",
    "          left_text = f'LEFT STEPS: {left_count}'\n",
    "          right_count = res['right']\n",
    "          right_text = f'RIGHT STEPS: {right_count}'\n",
    "          overall_count_as_str = str(left_count + right_count)\n",
    "          cv2.rectangle(image, (0, 0), (640,60), (255, 0, 0), -1)\n",
    "          cv2.putText(image,left_text, (50, 50), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "          cv2.putText(image,right_text, (300, 50), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "      #######################################################\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('error',e)\n",
    "        pass\n",
    "\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    flipped_frame = cv2.flip(image, 0)\n",
    "\n",
    "    cv2.imshow('MediaPipe Holistic',image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
