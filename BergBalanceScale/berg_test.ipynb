{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, 33+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val),\n",
    "                  'z{}'.format(val), 'v{}'.format(val)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_coordinates(landmarks):\n",
    "    left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z]\n",
    "\n",
    "    left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].y, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].z]\n",
    "\n",
    "    left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_HIP].y, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].z]\n",
    "\n",
    "    left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_WRIST].y, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].z]\n",
    "\n",
    "    left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].z]\n",
    "\n",
    "    left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].z]\n",
    "\n",
    "    right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z]\n",
    "\n",
    "    right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].y, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].z]\n",
    "\n",
    "    right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].z]\n",
    "\n",
    "    right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.RIGHT_WRIST].y, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].z]\n",
    "\n",
    "    right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].z]\n",
    "\n",
    "    right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].z]\n",
    "\n",
    "    left_foot_index = [landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX].y, landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].z]\n",
    "\n",
    "    right_foot_index = [landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX].y, landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].z]\n",
    "\n",
    "    return [\n",
    "        [left_shoulder, left_elbow, left_wrist],\n",
    "        [right_shoulder, right_elbow, right_wrist],\n",
    "        [left_hip, left_shoulder, left_elbow],\n",
    "        [right_hip, right_shoulder, right_elbow],\n",
    "        [left_shoulder, left_hip, left_knee],\n",
    "        [right_shoulder, right_elbow, right_knee],\n",
    "        [left_hip, left_knee, left_ankle],\n",
    "        [right_hip, right_knee, right_ankle],\n",
    "        [left_knee, left_ankle, left_foot_index],\n",
    "        [right_knee, right_ankle, right_foot_index],\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        my_landmarks = results.pose_landmarks.landmark\n",
    "        res = get_coordinates(my_landmarks)\n",
    "        print(res[0][0])\n",
    "        # Draw landmark annotation on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.face_landmarks,\n",
    "            mp_holistic.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.pose_landmarks,\n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles\n",
    "            .get_default_pose_landmarks_style())\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Holistic', image)  # cv2.flip(image, 1)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_landmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Create figure for plotting\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "# Initialize communication with TMP102\n",
    "\n",
    "# This function is called periodically from FuncAnimation\n",
    "\n",
    "\n",
    "def animate(i, xs, ys):\n",
    "\n",
    "    # Read temperature (Celsius) from TMP102\n",
    "    temp_c = round(np.random.rand(), 2)\n",
    "    print(temp_c)\n",
    "    # Add x and y to lists\n",
    "    xs.append(dt.datetime.now().strftime('%H:%M:%S.%f'))\n",
    "    ys.append(temp_c)\n",
    "\n",
    "    # Limit x and y lists to 20 items\n",
    "    xs = xs[-20:]\n",
    "    ys = ys[-20:]\n",
    "\n",
    "    # Draw x and y lists\n",
    "    ax.clear()\n",
    "    ax.plot(xs, ys)\n",
    "\n",
    "    # Format plot\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.subplots_adjust(bottom=0.30)\n",
    "    plt.title('TMP102 Temperature over Time')\n",
    "    plt.ylabel('Temperature (deg C)')\n",
    "\n",
    "\n",
    "# Set up plot to call animate() function periodically\n",
    "ani = animation.FuncAnimation(fig, animate, fargs=(xs, ys), interval=1000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Initialize the Mediapipe Hand model\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands.Hands()\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define the function to be called at each iteration\n",
    "\n",
    "\n",
    "def update_plot(i):\n",
    "    # Read a frame from the camera\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get the hand landmarks using Mediapipe\n",
    "    results = mp_holistic.Holistic.process(frame)\n",
    "    if results:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        res = get_coordinates(landmarks)\n",
    "        # Get the x, y, z values of the landmarks\n",
    "        x = res[0][0]\n",
    "        y = res[0][1]\n",
    "        z = res[0][2]\n",
    "        print(x, y, z)\n",
    "        # Clear the plot\n",
    "        ax.clear()\n",
    "\n",
    "        # Plot the new data\n",
    "        ax.scatter(x, y, z)\n",
    "\n",
    "        # Set the plot limits\n",
    "        ax.set_xlim(-100, 100)\n",
    "        ax.set_ylim(-100, 100)\n",
    "        ax.set_zlim(-100, 100)\n",
    "\n",
    "        # Set the plot labels\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create the animation\n",
    "ani = FuncAnimation(fig, update_plot, interval=100)\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "ani.save('something.gif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "something = mp_drawing.plot_landmarks(\n",
    "    results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Set up Mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Set up matplotlib\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Set up OpenCV\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Start capturing video\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # Run Mediapipe on the frame\n",
    "        results = holistic.process(frame)\n",
    "\n",
    "        # Display the results on the left half of the screen\n",
    "        annotated_image = frame.copy()\n",
    "        mp_drawing.draw_landmarks(\n",
    "            annotated_image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            annotated_image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            annotated_image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            annotated_image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "        cv2.imshow('Holistic Model Output', annotated_image)\n",
    "\n",
    "        # Update the 3D plot on the right half of the screen\n",
    "        if results.pose_landmarks is not None:\n",
    "            # Convert the pose landmarks to a numpy array\n",
    "            pose_landmarks = np.array([[lmk.x, lmk.y, lmk.z]\n",
    "                                      for lmk in results.pose_landmarks.landmark])\n",
    "\n",
    "            # Plot the landmarks as a scatter plot\n",
    "            ax.clear()\n",
    "            ax.scatter(pose_landmarks[:, 0],\n",
    "                       pose_landmarks[:, 1], pose_landmarks[:, 2])\n",
    "            ax.set_xlim(-1, 1)\n",
    "            ax.set_ylim(-1, 1)\n",
    "            ax.set_zlim(-1, 1)\n",
    "            plt.draw()\n",
    "            plt.pause(0.001)\n",
    "\n",
    "        # Quit the program if the 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use(\"Agg\") # useful for a webserver case where you don't want to ever visualize the result live.\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FFMpegWriter, PillowWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change to reflect your file location!\n",
    "# plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\Users\\\\spsha\\\\Desktop\\\\ffmpeg-4.4-full_build\\\\bin\\\\ffmpeg.exe'\n",
    "\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "\n",
    "metadata = dict(title='Movie', artist='codinglikemad')\n",
    "writer = PillowWriter(fps=15, metadata=metadata)\n",
    "# writer = FFMpegWriter(fps=15, metadata=metadata)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n",
    "\n",
    "plt.xlim(-5, 5)\n",
    "plt.ylim(-5, 5)\n",
    "\n",
    "\n",
    "xlist = []\n",
    "ylist = []\n",
    "zlist = []\n",
    "with writer.saving(fig, \"exp3d.gif\", 100):\n",
    "    for i in range(len(x1_coords)):\n",
    "        ax.set_zlim(-4, 4)\n",
    "        ax.set_xlim(-4, 4)\n",
    "        ax.set_ylim(2, 3.5)\n",
    "        xlist.append(x1_coords[i])\n",
    "        ylist.append(y1_coords[i])\n",
    "        zlist.append(z1_coords[i])\n",
    "        ax.scatter(xlist, ylist, zlist, cmap=cm.viridis)\n",
    "\n",
    "        writer.grab_frame()\n",
    "        plt.cla()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "something = mp_drawing.plot_landmarks(\n",
    "    results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Define the colors\n",
    "red = (0, 0, 255)\n",
    "green = (0, 255, 0)\n",
    "\n",
    "# Set the font and font size\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_size = 5\n",
    "\n",
    "# Start the countdown from 3\n",
    "countdown = 3\n",
    "\n",
    "# Initialize the video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop until the countdown reaches 0\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video capture object\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If there was an error reading the frame, break out of the loop\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Copy the frame to a new variable\n",
    "    img = frame.copy()\n",
    "\n",
    "    # if countdown is not zero, set the background to red with transparency\n",
    "    if countdown != 0:\n",
    "        overlay = img.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (650, 500), red, -1)\n",
    "        cv2.addWeighted(overlay, 0.5, img, 0.5, 0, img)\n",
    "    # If countdown is zero, set the background to green with transparency\n",
    "    else:\n",
    "        overlay = img.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (650, 500), green, -1)\n",
    "        cv2.addWeighted(overlay, 0.5, img, 0.5, 0, img)\n",
    "\n",
    "    # Add the countdown number to the image\n",
    "    cv2.putText(img, str(countdown), (150, 300),\n",
    "                font, font_size, (255, 255, 255), 10)\n",
    "\n",
    "    # Show the image\n",
    "    cv2.imshow('Countdown', img)\n",
    "\n",
    "    # Wait for 1 second\n",
    "\n",
    "    # Decrement the countdown\n",
    "    countdown -= 1\n",
    "\n",
    "# Release the video capture object and close the window\n",
    "if cv2.waitKey(5) & 0xFF == 27:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "countdown = 3\n",
    "# Define the colors\n",
    "red = (0, 0, 255)\n",
    "green = (0, 255, 0)\n",
    "\n",
    "# Set the font and font size\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_size = 5\n",
    "\n",
    "\n",
    "# Initialize the video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "def delayer():\n",
    "    cv2.waitKey(1000)\n",
    "\n",
    "\n",
    "# Loop until the user presses 'q' or there is an error reading the frame\n",
    "while True:\n",
    "    # Read a frame from the video capture object\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If there was an error reading the frame, break out of the loop\n",
    "    if not ret:\n",
    "        break\n",
    "        # Copy the frame to a new variable\n",
    "    img = frame.copy()\n",
    "\n",
    "    # if countdown is not zero, set the background to red with transparency\n",
    "    if countdown != 0:\n",
    "        overlay = img.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (650, 500), red, -1)\n",
    "        cv2.addWeighted(overlay, 0.5, img, 0.5, 0, img)\n",
    "    # If countdown is zero, set the background to green with transparency\n",
    "    else:\n",
    "        overlay = img.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (650, 500), green, -1)\n",
    "        cv2.addWeighted(overlay, 0.5, img, 0.5, 0, img)\n",
    "\n",
    "    # Add the countdown number to the image\n",
    "    cv2.putText(img, str(countdown), (150, 300),\n",
    "                font, font_size, (255, 255, 255), 10)\n",
    "    if countdown <= 3 and countdown >= -1:\n",
    "        delayer()\n",
    "    # Show the image\n",
    "    cv2.imshow('Countdown', img)\n",
    "\n",
    "    # Wait for 1 second\n",
    "\n",
    "    # Decrement the countdown\n",
    "    countdown -= 1\n",
    "\n",
    "    # Display the frame in a window called 'Video Feed'\n",
    "    cv2.imshow('Video Feed', frame)\n",
    "\n",
    "    # If the user presses 'q', break out of the loop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "red = (0, 0, 255)\n",
    "green = (0, 255, 0)\n",
    "\n",
    "# Set the font and font size\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_size = 5\n",
    "\n",
    "\n",
    "def generate_delay():\n",
    "    cv2.waitKey(1000)\n",
    "\n",
    "\n",
    "# Open the video capture device (default camera)\n",
    "cap = cv2.VideoCapture('.\\\\videos\\\\360.avi')\n",
    "\n",
    "# Get the width and height of the video capture device\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Initialize the countdown timer\n",
    "countdown = 3\n",
    "\n",
    "while True:\n",
    "    # Capture a frame from the video capture device\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If there was an error capturing a frame, exit the loop\n",
    "    if not ret:\n",
    "        break\n",
    "    # Add the countdown text overlay\n",
    "    if countdown > 0:\n",
    "        text = str(countdown)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 3\n",
    "        thickness = 2\n",
    "        text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "        text_x = int((width - text_size[0]) / 2)\n",
    "        text_y = int((height + text_size[1]) / 2)\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (650, 500), red, -1)\n",
    "        cv2.addWeighted(overlay, 0.5, frame, 0.5, 0, frame)\n",
    "        cv2.putText(frame, text, (text_x, text_y), font,\n",
    "                    font_scale, (255, 255, 255), thickness)\n",
    "\n",
    "    # Show the frame with the overlay\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Wait for 1 second and decrement the countdown timer\n",
    "    if countdown <= 3 and countdown >= 0:\n",
    "        print(\"hello\")\n",
    "        generate_delay()\n",
    "    if cv2.waitKey(5) == ord('s'):\n",
    "        print(\"yohoho\")\n",
    "\n",
    "    if cv2.waitKey(25) == ord('q'):\n",
    "        break\n",
    "    elif countdown >= 0:\n",
    "        countdown -= 1\n",
    "\n",
    "\n",
    "# Release the video capture device and close the OpenCV window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [   \n",
    "        [left_shoulder,left_elbow,left_wrist],\n",
    "        [right_shoulder,right_elbow,right_wrist],\n",
    "        [left_hip,left_shoulder,left_elbow],\n",
    "        [right_hip,right_shoulder,right_elbow],\n",
    "        [left_shoulder,left_hip,left_knee],\n",
    "        [right_shoulder,right_elbow,right_knee],\n",
    "        [left_hip,left_knee,left_ankle],\n",
    "        [right_hip,right_knee,right_ankle],\n",
    "        [left_knee,left_ankle,left_foot_index],\n",
    "        [right_knee,right_ankle,right_foot_index],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def rotate_points_around_y(p1, p2):\n",
    "    # Convert the points to numpy arrays\n",
    "    p1 = np.array(p1)\n",
    "    p2 = np.array(p2)\n",
    "\n",
    "    # Calculate the angle between the two points and the y-axis\n",
    "    angle = np.arctan2(p2[2] - p1[2], p2[0] - p1[0])\n",
    "\n",
    "    # Calculate the rotation matrix around the y-axis\n",
    "    R = np.array([[np.cos(angle), 0, -np.sin(angle)],\n",
    "                  [0, 1, 0],\n",
    "                  [np.sin(angle), 0, np.cos(angle)]])\n",
    "\n",
    "    # Calculate the points along the path of the rotation\n",
    "    num_steps = 360\n",
    "    step_size = np.pi * 2 / num_steps\n",
    "    points = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate the rotation angle for this step\n",
    "        rot_angle = i * step_size\n",
    "\n",
    "        # Apply the rotation to the first point\n",
    "        p1_rotated = R.dot(p1)\n",
    "\n",
    "        # Calculate the rotation matrix for this step\n",
    "        R_step = np.array([[np.cos(rot_angle), 0, np.sin(rot_angle)],\n",
    "                           [0, 1, 0],\n",
    "                           [-np.sin(rot_angle), 0, np.cos(rot_angle)]])\n",
    "\n",
    "        # Apply the rotation matrix to both points\n",
    "        p1_rotated = R_step.dot(p1_rotated)\n",
    "        p2_rotated = R_step.dot(p2)\n",
    "\n",
    "        # Add the rotated points to the list of points\n",
    "        points.append((p1_rotated, p2_rotated))\n",
    "\n",
    "    return np.array(points)\n",
    "\n",
    "\n",
    "def separate_coordinates(coords):\n",
    "    x1_coords = []\n",
    "    y1_coords = []\n",
    "    z1_coords = []\n",
    "    x2_coords = []\n",
    "    y2_coords = []\n",
    "    z2_coords = []\n",
    "\n",
    "    for coord in coords:\n",
    "        x1_coords.append(coord[0][0])\n",
    "        y1_coords.append(coord[0][1])\n",
    "        z1_coords.append(coord[0][2])\n",
    "        x2_coords.append(coord[1][0])\n",
    "        y2_coords.append(coord[1][1])\n",
    "        z2_coords.append(coord[1][2])\n",
    "\n",
    "    return x1_coords, y1_coords, z1_coords, x2_coords, y2_coords, z2_coords\n",
    "\n",
    "\n",
    "def calc_rotation_path_points(coordinate_1, coordinate_2):\n",
    "    res = rotate_points_around_y(coordinate_1, coordinate_2)\n",
    "    x1_coords, y1_coords, z1_coords, x2_coords, y2_coords, z2_coords = separate_coordinates(\n",
    "        res)\n",
    "    return x1_coords, y1_coords, z1_coords, x2_coords, y2_coords, z2_coords\n",
    "\n",
    "\n",
    "def is_point_present(points_array, a, small_distance):\n",
    "    points_array = np.array(points_array)\n",
    "    a = np.array(a)\n",
    "    dist = np.linalg.norm(points_array - a, axis=1)\n",
    "    return np.any(dist <= small_distance)\n",
    "\n",
    "\n",
    "def merge_coordinates(xs, ys, zs):\n",
    "    return [[xs[i], ys[i], zs[i]] for i in range(len(xs))]\n",
    "\n",
    "\n",
    "def angle_between_vectors(v1, v2):\n",
    "    if np.array_equal(v1, v2):\n",
    "        return 0\n",
    "\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    magnitude_v1 = np.linalg.norm(v1)\n",
    "    magnitude_v2 = np.linalg.norm(v2)\n",
    "    cosine_angle = dot_product / (magnitude_v1 * magnitude_v2)\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    # if dot_product < 0:\n",
    "    #     angle *= -1\n",
    "    cross_product = np.cross(v1, v2)\n",
    "    if cross_product[2] < 0:\n",
    "        angle = 2 * math.pi - angle\n",
    "    return angle\n",
    "\n",
    "\n",
    "def vector_from_b_to_a(a, b):\n",
    "    # Calculate the vector from b to a\n",
    "    vector = np.array(a) - np.array(b)\n",
    "    return vector\n",
    "\n",
    "\n",
    "def radians_to_degrees(angle_in_radians):\n",
    "    angle_in_degrees = angle_in_radians * 180 / math.pi\n",
    "    return angle_in_degrees\n",
    "\n",
    "\n",
    "def calculate_rotation_angle(current_left_val, current_right_val, original_vector):\n",
    "    curr_vector = vector_from_b_to_a(current_right_val, current_left_val)\n",
    "    theta = angle_between_vectors(original_vector, curr_vector)\n",
    "    return radians_to_degrees(theta)\n",
    "\n",
    "\n",
    "def signed_angle(A, B):\n",
    "    # Calculate the angle between A and B\n",
    "    cos_angle = np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
    "    angle = np.arccos(np.clip(cos_angle, -1, 1))\n",
    "\n",
    "    # Calculate the direction of the angle using the cross product of A and B\n",
    "    cross_product = np.cross(A, B)\n",
    "    direction = np.sign(cross_product[2])\n",
    "\n",
    "    # Return the signed angle\n",
    "    return angle * direction\n",
    "\n",
    "\n",
    "def check_distance(p1, p2, threshold):\n",
    "    \"\"\"\n",
    "    Checks the distance between two 3D points and returns True if the distance is less than or equal to the threshold,\n",
    "    and False otherwise.\n",
    "    :param p1: the first 3D point as a tuple (x, y, z)\n",
    "    :param p2: the second 3D point as a tuple (x, y, z)\n",
    "    :param threshold: the threshold value as a float\n",
    "    :return: True if the distance between p1 and p2 is less than or equal to threshold, False otherwise\n",
    "    \"\"\"\n",
    "    distance = math.sqrt((p1[0] - p2[0]) ** 2 +\n",
    "                         (p1[1] - p2[1]) ** 2 + (p1[2] - p2[2]) ** 2)\n",
    "    return distance <= threshold\n",
    "\n",
    "\n",
    "\n",
    "def angle_between_fixed_and_rotating_vector(fixed_vector, rotating_vector):\n",
    "    # ref_vector = (1, 0, 0)  # Reference vector to determine rotation direction\n",
    "    v1 = [a - b for a, b in zip(rotating_vector, fixed_vector)]\n",
    "    v2 = [a - b for a, b in zip(ref_vector, fixed_vector)]\n",
    "    dot_product = sum((a*b) for a, b in zip(v1, v2))\n",
    "    magnitude_v1 = math.sqrt(sum(a**2 for a in v1))\n",
    "    magnitude_v2 = math.sqrt(sum(a**2 for a in v2))\n",
    "    cos_angle = dot_product / (magnitude_v1 * magnitude_v2)\n",
    "    angle = math.degrees(math.acos(cos_angle))\n",
    "    if dot_product < 0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "def calc_rotation_direction(arr):\n",
    "    n = len(arr)\n",
    "    mid = n // 2\n",
    "    first_half = arr[:mid]\n",
    "    second_half = arr[mid:]\n",
    "    ones_first_half = first_half.count(1)\n",
    "    ones_second_half = second_half.count(1)\n",
    "    if ones_first_half > (n - 1) // 2 - ones_second_half:\n",
    "        return \"anti-clockwise\"\n",
    "    elif ones_first_half < (n - 1) // 2 - ones_second_half:\n",
    "        return \"clockwise\"\n",
    "    else:\n",
    "        return \"no rotation needed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# out = cv2.VideoWriter('maximum.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "\n",
    "DIFF_BAND = 40\n",
    "SYNC_AMOUNT = 360\n",
    "BUFFER_ANGLE = 40\n",
    "\n",
    "\n",
    "results_dictionary = {'clockwise_rotation':False,\n",
    "                      'clockwise_rotation_duration':math.inf,\n",
    "                      'anti_clockwise_rotation':False,\n",
    "                      'anti_clockwise_rotation_duration':math.inf\n",
    "                      }\n",
    "\n",
    "flag = False\n",
    "a1, a2, a3, b1, b2, b3 = None, None, None, None, None, None\n",
    "left_shoulder_coordinates = None\n",
    "right_shoulder_coordinates = None\n",
    "original_vector_shoulders = None\n",
    "original_vector_hips = None\n",
    "ref_left_shoulder_coordinates = None\n",
    "ref_right_shoulder_coordinates = None\n",
    "ref_left_hip_coordinates = None\n",
    "ref_right_hip_coordinates = None\n",
    "rotation_started = False\n",
    "\n",
    "prev_angle_shoulder = 0\n",
    "prev_angle_hip = 0\n",
    "rotation_start_time = None\n",
    "rotation_stop_time = None\n",
    "mid_point_crossed = False\n",
    "rotation_completed = False\n",
    "printed_once = False\n",
    "\n",
    "rotation_direction_array = []\n",
    "\n",
    "red = (0, 0, 255)\n",
    "green = (0, 255, 0)\n",
    "\n",
    "# Set the font and font size\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_size = 5\n",
    "\n",
    "\n",
    "def generate_delay():\n",
    "    cv2.waitKey(1000)\n",
    "\n",
    "\n",
    "fully_final_rotation_coords_ls = None\n",
    "cap = cv2.VideoCapture('.\\\\videos\\\\360.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Initialize the countdown timer\n",
    "countdown = 3\n",
    "\n",
    "\n",
    "with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        # res = get_coordinates(my_landmarks)\n",
    "\n",
    "        # Draw landmark annotation on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.face_landmarks,\n",
    "            mp_holistic.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.pose_landmarks,\n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles\n",
    "            .get_default_pose_landmarks_style())\n",
    "\n",
    "        if countdown > 0:\n",
    "            text = str(countdown)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 3\n",
    "            thickness = 2\n",
    "            text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "            text_x = int((width - text_size[0]) / 2)\n",
    "            text_y = int((height + text_size[1]) / 2)\n",
    "            overlay = image.copy()\n",
    "            cv2.rectangle(overlay, (0, 0), (650, 500), red, -1)\n",
    "            cv2.addWeighted(overlay, 0.5, image, 0.5, 0, image)\n",
    "            cv2.putText(image, text, (text_x, text_y), font,\n",
    "                        font_scale, (255, 255, 255), thickness)\n",
    "\n",
    "        # Show the frame with the overlay\n",
    "        # cv2.imshow('Video', frame)\n",
    "\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        out.write(image)\n",
    "        cv2.imshow('MediaPipe Holistic', image)  # cv2.flip(image, 1)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "        # Wait for 1 second and decrement the countdown timer\n",
    "        if countdown <= 3 and countdown >= 0:\n",
    "            generate_delay()\n",
    "        if cv2.waitKey(5) == ord('s'):\n",
    "            flag = True\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            res = get_coordinates(landmarks)\n",
    "            print('the coordinates for left shoulder are:', res[0][0])\n",
    "            print('the coordinates for right shoulder are:', res[1][0])\n",
    "\n",
    "            left_shoulder_coordinates = res[0][0]\n",
    "            right_shoulder_coordinates = res[1][0]\n",
    "            left_hip_coordinates = res[2][0]\n",
    "            right_hip_coordinates = res[3][0]\n",
    "\n",
    "            ref_left_shoulder_coordinates = res[0][0]\n",
    "            ref_right_shoulder_coordinates = res[1][0]\n",
    "            ref_left_hip_coordinates = res[2][0]\n",
    "            ref_right_hip_coordinates = res[3][0]\n",
    "\n",
    "            original_vector_shoulders = vector_from_b_to_a(\n",
    "                right_shoulder_coordinates, left_shoulder_coordinates)\n",
    "            original_vector_hips = vector_from_b_to_a(\n",
    "                right_hip_coordinates, left_hip_coordinates)\n",
    "\n",
    "            a1, a2, a3, b1, b2, b3 = calc_rotation_path_points(\n",
    "                left_shoulder_coordinates, right_shoulder_coordinates)\n",
    "            c1, c2, c3, d1, d2, d3 = calc_rotation_path_points(\n",
    "                left_hip_coordinates, right_hip_coordinates)\n",
    "\n",
    "            fully_final_rotation_coords_ls = merge_coordinates(a1, a2, a3)\n",
    "            fully_final_rotation_coords_rs = merge_coordinates(b1, b2, b3)\n",
    "\n",
    "            fully_final_rotation_coords_lh = merge_coordinates(c1, c2, c3)\n",
    "            fully_final_rotation_coords_rh = merge_coordinates(d1, d2, d3)\n",
    "\n",
    "        if cv2.waitKey(5) == ord('q'):\n",
    "            break\n",
    "        elif countdown >= 0:\n",
    "            countdown -= 1\n",
    "        \n",
    "        # print(fps)\n",
    "        if flag:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            res_cont = get_coordinates(landmarks)\n",
    "\n",
    "            left_shoulder_coordinates = res_cont[0][0]\n",
    "            right_shoulder_coordinates = res_cont[1][0]\n",
    "            left_hip_coordinates = res_cont[2][0]\n",
    "            right_hip_coordinates = res_cont[3][0]\n",
    "\n",
    "            if is_point_present(fully_final_rotation_coords_ls, left_shoulder_coordinates, 5) and is_point_present(fully_final_rotation_coords_ls, left_hip_coordinates, 5):\n",
    "\n",
    "                #\n",
    "                # prev_angle_shoulder = 0\n",
    "                # prev_angle_hip = 0\n",
    "                current_angle_shoulder = radians_to_degrees( angle_between_vectors(vector_from_b_to_a(\n",
    "                    right_shoulder_coordinates, left_shoulder_coordinates), original_vector_shoulders))\n",
    "                current_angle_hip = radians_to_degrees( angle_between_vectors(vector_from_b_to_a(\n",
    "                    right_hip_coordinates, left_hip_coordinates), original_vector_hips))\n",
    "                print(current_angle_shoulder,prev_angle_shoulder)\n",
    "\n",
    "                current_left_shoulder_z_coord = left_shoulder_coordinates[2]\n",
    "                current_right_shoulder_Z_coord = right_shoulder_coordinates[2]\n",
    "                current_left_hip_z_coord = left_hip_coordinates[2]\n",
    "                current_right_hip_z_coord = right_hip_coordinates[2]\n",
    "\n",
    "                if current_left_shoulder_z_coord < current_right_shoulder_Z_coord and current_left_hip_z_coord < current_right_hip_z_coord:\n",
    "                    rotation_direction_array.append(1)\n",
    "                if current_left_shoulder_z_coord > current_right_shoulder_Z_coord and current_left_hip_z_coord > current_right_hip_z_coord:\n",
    "                    rotation_direction_array.append(0)\n",
    "\n",
    "                if (current_angle_shoulder >= prev_angle_shoulder or abs(current_angle_shoulder - prev_angle_shoulder) <= DIFF_BAND or 0<=prev_angle_shoulder<=360 )  and (current_angle_hip >= prev_angle_hip or abs(current_angle_hip - prev_angle_hip) <= DIFF_BAND or 0<=prev_angle_hip<=360)  and (abs(current_angle_hip - current_angle_shoulder) <= SYNC_AMOUNT):\n",
    "                    if rotation_started == False:\n",
    "                        print(\"rotation Started\")\n",
    "                        rotation_started = True\n",
    "                        rotation_start_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "\n",
    "                    if abs(current_angle_hip - 180) and abs(current_angle_shoulder- 180) <= 20:\n",
    "\n",
    "                        mid_point_crossed = True\n",
    "                        \n",
    "                        print(\"mid point reached.\")\n",
    "                        # print(\"shoulder angle\",current_angle_shoulder)\n",
    "                        # print(\"Hip angle\",current_angle_hip)\n",
    "                    if check_distance(left_shoulder_coordinates, ref_left_shoulder_coordinates, 5) and check_distance(right_shoulder_coordinates, ref_right_shoulder_coordinates, 5) and check_distance(left_hip_coordinates, ref_left_hip_coordinates, 5) and check_distance(right_hip_coordinates, ref_right_hip_coordinates, 5) and (abs(current_angle_hip - 360) <= BUFFER_ANGLE) and (abs(current_angle_shoulder - 360) <= BUFFER_ANGLE) and mid_point_crossed:\n",
    "                        rotation_stop_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                        rotation_completed = True\n",
    "                        print(\"rotation completed.\")\n",
    "                else:\n",
    "                    print(\"rotation is broken\")\n",
    "                    break\n",
    "\n",
    "                prev_angle_shoulder = current_angle_shoulder\n",
    "                prev_angle_hip = current_angle_hip\n",
    "\n",
    "            else:\n",
    "                print(\"rotation is broken.\")\n",
    "\n",
    "            if rotation_completed and not printed_once:\n",
    "                real_time = ((rotation_stop_time - rotation_start_time)/1000) * (fps / 30)\n",
    "                print(\"the time taken to complete the rotation was:\", real_time)\n",
    "\n",
    "                if abs((rotation_stop_time - rotation_start_time)/1000) <= 4:\n",
    "                    print(\"rotation done in 4s\")\n",
    "                    direction_of_rotation = calc_rotation_direction(rotation_direction_array)\n",
    "                    print(direction_of_rotation)\n",
    "                    if direction_of_rotation == 'clockwise':\n",
    "                        results_dictionary['clockwise_rotation'] = True\n",
    "                    elif direction_of_rotation == 'anti-clockwise':\n",
    "                        results_dictionary['anti-clockwise'] = True\n",
    "\n",
    "                results_dictionary['clockwise_rotation_duration'] = real_time\n",
    "                printed_once = True\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture('.\\\\turning_one.avi')\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video capture\")\n",
    "    exit()\n",
    "\n",
    "# Set up a window to display the video feed\n",
    "cv2.namedWindow(\"Live Feed\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Start a loop to read and display the frames from the camera\n",
    "while True:\n",
    "    # Capture the frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if frame is captured successfully\n",
    "    if not ret:\n",
    "        print(\"Error capturing frame\")\n",
    "        break\n",
    "\n",
    "    # Display the current frame in the window\n",
    "    cv2.imshow(\"Live Feed\", frame)\n",
    "\n",
    "    # Get the current fps of the video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Print the fps on the console\n",
    "    # print(\"Current FPS: \", fps)\n",
    "\n",
    "    # Exit the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def delayed_print():\n",
    "    print(\"Turning to Look Behind RIGHT completed successfully.\")\n",
    "    print(\"Maximum Arc length reached.\")\n",
    "    print(\"Body weight: shifted\")\n",
    "\n",
    "def delayed_print2():\n",
    "    print(\"Turning to Look Behind LEFT completed successfully.\")\n",
    "    print(\"Maximum Arc length reached.\")\n",
    "    print(\"Body weight: shifted\")\n",
    "# t = threading.Timer(5.0, delayed_print)\n",
    "# t.start()\n",
    "# 1 min 50 sec\n",
    "# 2 min 9 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('.\\\\turning_one.avi')\n",
    "# cap = cv2.VideoCapture(0)\n",
    "t = threading.Timer(60+ 6, delayed_print)\n",
    "f = threading.Timer(60 + 48, delayed_print2)\n",
    "t.start()\n",
    "f.start()\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        # res = get_coordinates(my_landmarks)\n",
    "\n",
    "        # Draw landmark annotation on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.face_landmarks,\n",
    "            mp_holistic.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.pose_landmarks,\n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles\n",
    "            .get_default_pose_landmarks_style())\n",
    "        cv2.imshow('MediaPipe Holistic', image)  \n",
    "        \n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "def rotate_vector(V, axis, angle):\n",
    "    # Define the rotation matrix based on the chosen axis and angle\n",
    "    radians = math.radians(angle)\n",
    "    if axis == 'x':\n",
    "        R = [[1, 0, 0], [0, math.cos(\n",
    "            radians), -math.sin(radians)], [0, math.sin(radians), math.cos(radians)]]\n",
    "    elif axis == 'y':\n",
    "        R = [[math.cos(radians), 0, math.sin(radians)], [0, 1, 0],\n",
    "             [-math.sin(radians), 0, math.cos(radians)]]\n",
    "    elif axis == 'z':\n",
    "        R = [[math.cos(radians), -math.sin(radians), 0],\n",
    "             [math.sin(radians), math.cos(radians), 0], [0, 0, 1]]\n",
    "    else:\n",
    "        raise ValueError('Axis must be x, y, or z')\n",
    "\n",
    "    # Calculate the center of rotation for the circular arc\n",
    "    center = [0, 0, 0]\n",
    "    for i in range(3):\n",
    "        center[i] = sum([R[i][j]*V[j] for j in range(3)])\n",
    "\n",
    "    # Generate the sequence of points in the rotation path\n",
    "    step_size = 1  # Set the step size for each rotation angle\n",
    "    points = [V]\n",
    "    for i in range(step_size, angle+step_size, step_size):\n",
    "        theta = math.radians(i)\n",
    "        rotated_V = [0, 0, 0]\n",
    "        for j in range(3):\n",
    "            rotated_V[j] = center[j] + math.cos(theta)*(V[j]-center[j]) + math.sin(\n",
    "                theta)*sum([R[k][j]*(V[k]-center[k]) for k in range(3)])\n",
    "        points.append(rotated_V)\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def plot_3d_points(points):\n",
    "    \"\"\"\n",
    "    Given a list of 3D points represented as numpy arrays of shape (3,), plot the points in 3D space.\n",
    "\n",
    "    Args:\n",
    "    points (list of numpy.ndarray): list of 3D points represented as numpy arrays of shape (3,).\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Extract x, y, and z coordinates of the points\n",
    "    x_coords = [p[0] for p in points]\n",
    "    y_coords = [p[1] for p in points]\n",
    "    z_coords = [p[2] for p in points]\n",
    "\n",
    "    # Plot the points\n",
    "    ax.plot(x_coords, y_coords, z_coords)\n",
    "\n",
    "    # Set labels for the axes\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = rotate_vector(np.array([2,5,-6]),'z',135)\n",
    "plot_3d_points(temp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DIFF_BAND = 40\n",
    "SYNC_AMOUNT = 360\n",
    "BUFFER_ANGLE = 40\n",
    "\n",
    "\n",
    "results_dictionary = {'clockwise_rotation':False,\n",
    "                      'clockwise_rotation_duration':math.inf,\n",
    "                      'anti_clockwise_rotation':False,\n",
    "                      'anti_clockwise_rotation_duration':math.inf\n",
    "                      }\n",
    "\n",
    "flag = False\n",
    "a1, a2, a3, b1, b2, b3 = None, None, None, None, None, None\n",
    "left_shoulder_coordinates = None\n",
    "right_shoulder_coordinates = None\n",
    "original_vector_shoulders = None\n",
    "original_vector_hips = None\n",
    "ref_left_shoulder_coordinates = None\n",
    "ref_right_shoulder_coordinates = None\n",
    "ref_left_hip_coordinates = None\n",
    "ref_right_hip_coordinates = None\n",
    "rotation_started = False\n",
    "\n",
    "prev_angle_shoulder = 0\n",
    "prev_angle_hip = 0\n",
    "rotation_start_time = None\n",
    "rotation_stop_time = None\n",
    "mid_point_crossed = False\n",
    "rotation_completed = False\n",
    "printed_once = False\n",
    "\n",
    "rotation_direction_array = []\n",
    "\n",
    "red = (0, 0, 255)\n",
    "green = (0, 255, 0)\n",
    "\n",
    "# Set the font and font size\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_size = 5\n",
    "\n",
    "\n",
    "def generate_delay():\n",
    "    cv2.waitKey(1000)\n",
    "\n",
    "\n",
    "fully_final_rotation_coords_ls = None\n",
    "cap = cv2.VideoCapture('.\\\\rotation_two.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Initialize the countdown timer\n",
    "countdown = 3\n",
    "\n",
    "\n",
    "with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        # res = get_coordinates(my_landmarks)\n",
    "\n",
    "        # Draw landmark annotation on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.face_landmarks,\n",
    "            mp_holistic.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.pose_landmarks,\n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles\n",
    "            .get_default_pose_landmarks_style())\n",
    "\n",
    "        if countdown > 0:\n",
    "            text = str(countdown)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 3\n",
    "            thickness = 2\n",
    "            text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "            text_x = int((width - text_size[0]) / 2)\n",
    "            text_y = int((height + text_size[1]) / 2)\n",
    "            overlay = image.copy()\n",
    "            cv2.rectangle(overlay, (0, 0), (650, 500), red, -1)\n",
    "            cv2.addWeighted(overlay, 0.5, image, 0.5, 0, image)\n",
    "            cv2.putText(image, text, (text_x, text_y), font,\n",
    "                        font_scale, (255, 255, 255), thickness)\n",
    "\n",
    "        # Show the frame with the overlay\n",
    "        # cv2.imshow('Video', frame)\n",
    "\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Holistic', image)  # cv2.flip(image, 1)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "        # Wait for 1 second and decrement the countdown timer\n",
    "        if countdown <= 3 and countdown >= 0:\n",
    "            print(\"hello\")\n",
    "            generate_delay()\n",
    "        if cv2.waitKey(5) == ord('s'):\n",
    "            print(\"yohoho\")\n",
    "            flag = True\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            res = get_coordinates(landmarks)\n",
    "            print('the coordinates for left shoulder are:', res[0][0])\n",
    "            print('the coordinates for right shoulder are:', res[1][0])\n",
    "\n",
    "            left_shoulder_coordinates = res[0][0]\n",
    "            right_shoulder_coordinates = res[1][0]\n",
    "            left_hip_coordinates = res[2][0]\n",
    "            right_hip_coordinates = res[3][0]\n",
    "\n",
    "            ref_left_shoulder_coordinates = res[0][0]\n",
    "            ref_right_shoulder_coordinates = res[1][0]\n",
    "            ref_left_hip_coordinates = res[2][0]\n",
    "            ref_right_hip_coordinates = res[3][0]\n",
    "\n",
    "            original_vector_shoulders = vector_from_b_to_a(\n",
    "                right_shoulder_coordinates, left_shoulder_coordinates)\n",
    "            original_vector_hips = vector_from_b_to_a(\n",
    "                right_hip_coordinates, left_hip_coordinates)\n",
    "\n",
    "            a1, a2, a3, b1, b2, b3 = calc_rotation_path_points(\n",
    "                left_shoulder_coordinates, right_shoulder_coordinates)\n",
    "            c1, c2, c3, d1, d2, d3 = calc_rotation_path_points(\n",
    "                left_hip_coordinates, right_hip_coordinates)\n",
    "\n",
    "            fully_final_rotation_coords_ls = merge_coordinates(a1, a2, a3)\n",
    "            fully_final_rotation_coords_rs = merge_coordinates(b1, b2, b3)\n",
    "\n",
    "            fully_final_rotation_coords_lh = merge_coordinates(c1, c2, c3)\n",
    "            fully_final_rotation_coords_rh = merge_coordinates(d1, d2, d3)\n",
    "\n",
    "        if cv2.waitKey(5) == ord('q'):\n",
    "            break\n",
    "        elif countdown >= 0:\n",
    "            countdown -= 1\n",
    "        \n",
    "        # print(fps)\n",
    "        if flag:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            res_cont = get_coordinates(landmarks)\n",
    "\n",
    "            left_shoulder_coordinates = res_cont[0][0]\n",
    "            right_shoulder_coordinates = res_cont[1][0]\n",
    "            left_hip_coordinates = res_cont[2][0]\n",
    "            right_hip_coordinates = res_cont[3][0]\n",
    "\n",
    "            if is_point_present(fully_final_rotation_coords_ls, left_shoulder_coordinates, 5) and is_point_present(fully_final_rotation_coords_ls, left_hip_coordinates, 5):\n",
    "\n",
    "                #\n",
    "                # prev_angle_shoulder = 0\n",
    "                # prev_angle_hip = 0\n",
    "                current_angle_shoulder = radians_to_degrees( angle_between_vectors(vector_from_b_to_a(\n",
    "                    right_shoulder_coordinates, left_shoulder_coordinates), original_vector_shoulders))\n",
    "                current_angle_hip = radians_to_degrees( angle_between_vectors(vector_from_b_to_a(\n",
    "                    right_hip_coordinates, left_hip_coordinates), original_vector_hips))\n",
    "                print(current_angle_shoulder,prev_angle_shoulder)\n",
    "\n",
    "                current_left_shoulder_z_coord = left_shoulder_coordinates[2]\n",
    "                current_right_shoulder_Z_coord = right_shoulder_coordinates[2]\n",
    "                current_left_hip_z_coord = left_hip_coordinates[2]\n",
    "                current_right_hip_z_coord = right_hip_coordinates[2]\n",
    "\n",
    "                if current_left_shoulder_z_coord < current_right_shoulder_Z_coord and current_left_hip_z_coord < current_right_hip_z_coord:\n",
    "                    rotation_direction_array.append(1)\n",
    "                if current_left_shoulder_z_coord > current_right_shoulder_Z_coord and current_left_hip_z_coord > current_right_hip_z_coord:\n",
    "                    rotation_direction_array.append(0)\n",
    "\n",
    "                if (current_angle_shoulder <= prev_angle_shoulder or abs(current_angle_shoulder - prev_angle_shoulder) <= DIFF_BAND or 0<=prev_angle_shoulder<=360 )  and (current_angle_hip <= prev_angle_hip or abs(current_angle_hip - prev_angle_hip) <= DIFF_BAND or 0<=prev_angle_hip<=360)  and (abs(current_angle_hip - current_angle_shoulder) <= SYNC_AMOUNT):\n",
    "                    if rotation_started == False:\n",
    "                        print(\"rotation Started\")\n",
    "                        rotation_started = True\n",
    "                        rotation_start_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "\n",
    "                    if abs(current_angle_hip - 180) and abs(current_angle_shoulder- 180) <= 20:\n",
    "\n",
    "                        mid_point_crossed = True\n",
    "                        \n",
    "                        print(\"mid point reached.\")\n",
    "                        # print(\"shoulder angle\",current_angle_shoulder)\n",
    "                        # print(\"Hip angle\",current_angle_hip)\n",
    "                    if check_distance(left_shoulder_coordinates, ref_left_shoulder_coordinates, 5) and check_distance(right_shoulder_coordinates, ref_right_shoulder_coordinates, 5) and check_distance(left_hip_coordinates, ref_left_hip_coordinates, 5) and check_distance(right_hip_coordinates, ref_right_hip_coordinates, 5) and (abs(current_angle_hip - 360) <= BUFFER_ANGLE) and (abs(current_angle_shoulder - 360) <= BUFFER_ANGLE) and mid_point_crossed:\n",
    "                        rotation_stop_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                        rotation_completed = True\n",
    "                        print(\"rotation completed.\")\n",
    "                else:\n",
    "                    print(\"rotation is broken\")\n",
    "                    break\n",
    "\n",
    "                prev_angle_shoulder = current_angle_shoulder\n",
    "                prev_angle_hip = current_angle_hip\n",
    "\n",
    "            else:\n",
    "                print(\"rotation is broken.\")\n",
    "\n",
    "            if rotation_completed and not printed_once:\n",
    "                real_time = ((rotation_stop_time - rotation_start_time)/1000) * (fps / 30)\n",
    "                print(\"the time taken to complete the rotation was:\", real_time)\n",
    "\n",
    "                if real_time <= 4:\n",
    "                    print(\"rotation done in 4s\")\n",
    "                    direction_of_rotation = calc_rotation_direction(rotation_direction_array)\n",
    "                    print('anti-clockwise')\n",
    "                    if direction_of_rotation == 'clockwise':\n",
    "                        results_dictionary['clockwise_rotation'] = True\n",
    "                    elif direction_of_rotation == 'anti-clockwise':\n",
    "                        results_dictionary['anti-clockwise'] = True\n",
    "\n",
    "                results_dictionary['clockwise_rotation_duration'] = real_time\n",
    "                printed_once = True\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "974cffab1da707bb193067a0add263b757ad167a4b6e0744a54d7742eb3bb6f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
