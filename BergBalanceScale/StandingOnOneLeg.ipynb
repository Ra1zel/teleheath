{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, 33+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val),\n",
    "                  'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video_from_file('./videos/oneFoot.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_mediapipe_holistic_model('./videos/oneFoot.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standing_on_one_leg_grader(hold_time,fall_flag,other_person_flag):\n",
    "    if hold_time > 10:\n",
    "        return 4\n",
    "    elif 5 <= hold_time <= 10:\n",
    "        return 3\n",
    "    elif 3 <= hold_time < 5:\n",
    "        return 2\n",
    "    elif hold_time < 3 and not fall_flag:\n",
    "        return 1\n",
    "    elif other_person_flag:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "distance_band = 0.1\n",
    "cap = cv2.VideoCapture('./oneStepSide.avi')\n",
    "captured_video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_idx = 0\n",
    "start_time = cv2.getTickCount()\n",
    "\n",
    "#######GLOBALS##############\n",
    "history_array = []\n",
    "leg_raise_begin_time = None\n",
    "leg_raise_end_time = None\n",
    "tries = 0\n",
    "#########FLAGS##############\n",
    "fall_flag = False\n",
    "other_person_flag = False\n",
    "is_right_leg_lifted = False\n",
    "is_left_leg_lifted = False\n",
    "first_time = False\n",
    "############################\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    frame_idx+=1\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = holistic.process(image)\n",
    "\n",
    "    # Draw landmark annotation on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.pose_landmarks,\n",
    "        mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles\n",
    "        .get_default_pose_landmarks_style())\n",
    "    \n",
    "    try:\n",
    "      ######################################################\n",
    "      #Extract Joint coordinates\n",
    "      my_landmarks = results.pose_landmarks.landmark\n",
    "      joint_coordinates = get_coordinates(my_landmarks)\n",
    "      right_heel = [my_landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].x , my_landmarks[mp_pose.PoseLandmark.RIGHT_HEEL].y, my_landmarks[mp_pose.PoseLandmark.RIGHT_HEEL].z]\n",
    "      left_heel = [my_landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x , my_landmarks[mp_pose.PoseLandmark.LEFT_HEEL].y, my_landmarks[mp_pose.PoseLandmark.LEFT_HEEL].z]\n",
    "      left_ankle = joint_coordinates[6][2]\n",
    "      right_ankle = joint_coordinates[7][2]\n",
    "\n",
    "      # print(\"right heel are: \",right_heel,\" left heel are: \",left_heel)\n",
    "      \n",
    "      if right_ankle[1] - left_ankle[1] > distance_band:\n",
    "        print(\"left leg is lifted.\")\n",
    "        is_left_leg_lifted = True\n",
    "\n",
    "      if left_ankle[1] - right_ankle[1] > distance_band:\n",
    "        print(\"right leg is lifted.\")\n",
    "        is_right_leg_lifted = True\n",
    "      #############################\n",
    "\n",
    "      #############################\n",
    "      end_time = cv2.getTickCount()   \n",
    "      total_time = (end_time - start_time) / cv2.getTickFrequency()\n",
    "      # print(\"The fps is: \",frame_idx/total_time)\n",
    "      multiply_factor = 20/(frame_idx/total_time)\n",
    "      real_time = total_time/multiply_factor\n",
    "      cv2.rectangle(image, (0, 0), (640,60), (255, 0, 0), -1)\n",
    "      cv2.putText(image,str(real_time), (50, 50), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "      #################################################################\n",
    "      \n",
    "      if first_time:\n",
    "        now = real_time\n",
    "        time = now - leg_raise_begin_time\n",
    "        if time >=10:\n",
    "          print(\"The result for this exersize is: \",standing_on_one_leg_grader(time,fall_flag,other_person_flag))\n",
    "          break\n",
    "\n",
    "      if is_right_leg_lifted and not first_time:\n",
    "        leg_raise_begin_time = real_time\n",
    "        first_time = True\n",
    "        history_array.append('raised right')\n",
    "\n",
    "\n",
    "      if not is_right_leg_lifted and first_time:\n",
    "        leg_raise_end_time = real_time\n",
    "        first_time = False\n",
    "        history_array.append('normal right')\n",
    "\n",
    "      \n",
    "      if is_left_leg_lifted and not first_time:\n",
    "        leg_raise_begin_time = real_time\n",
    "        first_time = True\n",
    "        history_array.append('raised left')\n",
    "      \n",
    "      if not is_left_leg_lifted and first_time:\n",
    "        leg_raise_end_time = real_time\n",
    "        first_time = False\n",
    "        history_array.append('normal left')\n",
    "\n",
    "      \n",
    "      if leg_raise_end_time and leg_raise_begin_time:\n",
    "        time = leg_raise_end_time - leg_raise_begin_time\n",
    "        # print(\"The result for this exesize is: \",standing_on_one_leg_grader(time,fall_flag,other_person_flag))\n",
    "        result = standing_on_one_leg_grader(time,fall_flag,other_person_flag)\n",
    "        if result == 3:\n",
    "          print(\"The result for this exersize is: \",result)\n",
    "          break\n",
    "        elif result == 2:\n",
    "          print(\"The result for this exersize is: \",result)\n",
    "          break\n",
    "        elif result == 1:\n",
    "          print(\"The result for this exercize is: \",result)\n",
    "          break\n",
    "        elif result ==0:\n",
    "          tries +=1\n",
    "          if tries >= 3:\n",
    "            print(\"The result for this exersize is: \",result)\n",
    "            break\n",
    "      #################################################################\n",
    "    except Exception as e:\n",
    "        print('error',e)\n",
    "        pass\n",
    "\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    flipped_frame = cv2.flip(image, 0)\n",
    "\n",
    "    cv2.imshow('MediaPipe Holistic',image)\n",
    "    is_right_leg_lifted = False\n",
    "    is_left_leg_lifted = False\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
